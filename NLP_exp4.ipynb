{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Krisha Goti C035"
      ],
      "metadata": {
        "id": "jXhud97eFJg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B.1 Tasks given in PART A to be completed here**"
      ],
      "metadata": {
        "id": "pgZm5Xdfr30x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-processing and normalizing text"
      ],
      "metadata": {
        "id": "hPWBs3FZD1UT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeixF6Zdpm9D"
      },
      "outputs": [],
      "source": [
        "# creating a document\n",
        "documents = [\"Women bites cat.\", \"Cat bites women.\", \"Women eats meat.\", \"Cat eats food.\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting to lower case and replacing fullstops\n",
        "\n",
        "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
        "processed_docs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn-yp-XvCdcD",
        "outputId": "780eeea7-819e-466f-f553-6d18cdb36668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['women bites cat', 'cat bites women', 'women eats meat', 'cat eats food']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the vocabulary\n",
        "vocab = {}\n",
        "count = 0\n",
        "for doc in processed_docs:\n",
        "    for word in doc.split():\n",
        "        if word not in vocab:\n",
        "            count = count +1\n",
        "            vocab[word] = count\n",
        "print(vocab)\n",
        "{'women': 1, 'bites': 2, 'cat': 3, 'eats': 4, 'meat': 5, 'food': 6}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca5s_QKDCjY8",
        "outputId": "85ccb9bb-2dc6-4b56-d8b7-09a324a0ab81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'women': 1, 'bites': 2, 'cat': 3, 'eats': 4, 'meat': 5, 'food': 6}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'women': 1, 'bites': 2, 'cat': 3, 'eats': 4, 'meat': 5, 'food': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get one hot representation for any string based on this vocabulary. #If the word exists in the vocabulary, its representation is returned. #If not, a list of zeroes is returned for that word.\n",
        "def get_onehot_vector(somestring):\n",
        "    onehot_encoded = []\n",
        "    for word in somestring.split():\n",
        "        temp = [0]*len(vocab)\n",
        "        if word in vocab:\n",
        "            temp[vocab[word]-1] = 1 # -1 is to take care of the fact indexing in array starts from 0 and not 1\n",
        "        onehot_encoded.append(temp)\n",
        "    return onehot_encoded\n",
        "\n",
        "print(processed_docs[1])\n",
        "\n",
        "get_onehot_vector(processed_docs[1]) #one hot representation for a text from our corpus.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GNJFLJuCnfI",
        "outputId": "57809154-9409-40b3-f075-55148dd98c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat bites women\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_onehot_vector(\"cat and women are good\")\n",
        "#one hot representation for a random text, using the above vocabulary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C6HmdgdC4Bo",
        "outputId": "0a68b09a-89fd-475c-d81e-92b7bd59a5d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_onehot_vector(\"cat and cat are good\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHQnysmSC6pV",
        "outputId": "ae08c5f0-d06d-4118-8b83-e6d79ff92b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-hot encoding using scikit -learn\n"
      ],
      "metadata": {
        "id": "CNb1T3uUDO-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "S1 = 'women bites cat'\n",
        "S2 = 'cat bites women'\n",
        "S3 = 'women eats meat'\n",
        "S4 = 'cat eats food'\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "data = [S1.split(), S2.split(), S3.split(), S4.split()]\n",
        "values = data[0]+data[1]+data[2]+data[3]\n",
        "print(\"The data: \",values)\n",
        "\n",
        "#Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "print(\"Label Encoded:\",integer_encoded)\n",
        "\n",
        "#One-Hot Encoding\n",
        "onehot_encoder = OneHotEncoder()\n",
        "onehot_encoded = onehot_encoder.fit_transform(data).toarray()\n",
        "print(\"Onehot Encoded Matrix:\\n\",onehot_encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqPrNKJcDACt",
        "outputId": "01f5fd72-c105-437b-a7ba-3e82f68a243b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data:  ['women', 'bites', 'cat', 'cat', 'bites', 'women', 'women', 'eats', 'meat', 'cat', 'eats', 'food']\n",
            "Label Encoded: [5 0 1 1 0 5 5 2 4 1 2 3]\n",
            "Onehot Encoded Matrix:\n",
            " [[0. 1. 1. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 1. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 1. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 1. 0. 1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of Words"
      ],
      "metadata": {
        "id": "pyQzMG1oDRzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#look at the documents list\n",
        "print(\"Our corpus: \", processed_docs)\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "#Build a BOW representation for the corpus\n",
        "bow_rep = count_vect.fit_transform(processed_docs)\n",
        "\n",
        "#Look at the vocabulary mapping\n",
        "print(\"Our vocabulary: \", count_vect.vocabulary_)\n",
        "\n",
        "#see the BOW rep for first 2 documents\n",
        "print(\"BoW representation for 'women bites cat': \", bow_rep[0].toarray())\n",
        "print(\"BoW representation for 'cat bites women: \",bow_rep[1].toarray())\n",
        "\n",
        "#Get the representation using this vocabulary, for a new text\n",
        "temp = count_vect.transform([\"women and women are friends\"])\n",
        "print(\"Bow representation for 'women and women are friends':\", temp.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuYBqwbrDUxt",
        "outputId": "e9286018-c670-48ae-f1c3-9ea9dc60be71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our corpus:  ['women bites cat', 'cat bites women', 'women eats meat', 'cat eats food']\n",
            "Our vocabulary:  {'women': 5, 'bites': 0, 'cat': 1, 'eats': 2, 'meat': 4, 'food': 3}\n",
            "BoW representation for 'women bites cat':  [[1 1 0 0 0 1]]\n",
            "BoW representation for 'cat bites women:  [[1 1 0 0 0 1]]\n",
            "Bow representation for 'women and women are friends': [[0 0 0 0 0 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of N grams\n"
      ],
      "metadata": {
        "id": "WQBpuTzEDa3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#Ngram vectorization example with count vectorizer and uni, bi, trigrams\n",
        "count_vect = CountVectorizer(ngram_range=(1,3))\n",
        "\n",
        "#Build a BOW representation for the corpus\n",
        "bow_rep = count_vect.fit_transform(processed_docs)\n",
        "\n",
        "#Look at the vocabulary mapping\n",
        "print(\"Our vocabulary: \", count_vect.vocabulary_)\n",
        "\n",
        "#see the BOW rep for first 2 documents\n",
        "print(\"BoW representation for 'women bites cat': \", bow_rep[0].toarray())\n",
        "print(\"BoW representation for 'cat bites women: \",bow_rep[1].toarray())\n",
        "\n",
        "#Get the representation using this vocabulary, for a new text\n",
        "temp = count_vect.transform([\"women and women are friends\"])\n",
        "\n",
        "print(\"Bow representation for 'women and women are friends':\", temp.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-hISoIKDbyw",
        "outputId": "0c9f67f5-d972-4c8d-c5cb-a20d1906797f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our vocabulary:  {'women': 13, 'bites': 0, 'cat': 3, 'women bites': 14, 'bites cat': 1, 'women bites cat': 15, 'cat bites': 4, 'bites women': 2, 'cat bites women': 5, 'eats': 8, 'meat': 12, 'women eats': 16, 'eats meat': 10, 'women eats meat': 17, 'food': 11, 'cat eats': 6, 'eats food': 9, 'cat eats food': 7}\n",
            "BoW representation for 'women bites cat':  [[1 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0]]\n",
            "BoW representation for 'cat bites women:  [[1 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0]]\n",
            "Bow representation for 'women and women are friends': [[0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF"
      ],
      "metadata": {
        "id": "yO2j_BzJDgek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "bow_rep_tfidf = tfidf.fit_transform(processed_docs)\n",
        "\n",
        "#IDF for all words in the vocabulary\n",
        "print(\"IDF for all words in the vocabulary\",tfidf.idf_)\n",
        "print(\"-\"*10)\n",
        "#All words in the vocabulary.\n",
        "print(\"All words in the vocabulary\",tfidf.get_feature_names())\n",
        "print(\"-\"*10)\n",
        "\n",
        "#TFIDF representation for all documents in our corpus\n",
        "print(\"TFIDF representation for all documents in our corpus\\n\",bow_rep_tfidf.toarray())\n",
        "print(\"-\"*10)\n",
        "\n",
        "temp = tfidf.transform([\"women and man are friends\"])\n",
        "print(\"Tfidf representation for 'women and cat are friends':\\n\", temp.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUifYeN_DhLn",
        "outputId": "f1b41dc7-5d8e-40be-86d8-88fc1091b21c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IDF for all words in the vocabulary [1.51082562 1.22314355 1.51082562 1.91629073 1.91629073 1.22314355]\n",
            "----------\n",
            "All words in the vocabulary ['bites', 'cat', 'eats', 'food', 'meat', 'women']\n",
            "----------\n",
            "TFIDF representation for all documents in our corpus\n",
            " [[0.65782931 0.53256952 0.         0.         0.         0.53256952]\n",
            " [0.65782931 0.53256952 0.         0.         0.         0.53256952]\n",
            " [0.         0.         0.55349232 0.         0.70203482 0.44809973]\n",
            " [0.         0.44809973 0.55349232 0.70203482 0.         0.        ]]\n",
            "----------\n",
            "Tfidf representation for 'women and cat are friends':\n",
            " [[0. 0. 0. 0. 0. 1.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B.2 Observations and Learning:**"
      ],
      "metadata": {
        "id": "iiUJVZJ8r9xo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this experiment we have observed and studied about Feature Engineering of textual data using (a) One hot encoding (b) Bag of words (BoW) (c) Bag of n-grams (D) TF-IDF"
      ],
      "metadata": {
        "id": "Vl3bQAiqsA3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B.3 Conclusion:**"
      ],
      "metadata": {
        "id": "crzrrt-xsBW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After successfully completing this experiment we are able to:\n",
        "Understand the feature vector representation of textual data\n",
        "Design, Implement and test models for different NLP applications using statistical and sequence models.\n"
      ],
      "metadata": {
        "id": "O_S8gIWJsDpG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B.4 Question of curiosity:**\n"
      ],
      "metadata": {
        "id": "grxj_ffEsHvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is the advantage of representing text as numeric data?\n",
        "\n",
        "Representing text as numerical data has several advantages, including:\n",
        "* Better compatibility with data analysis tools: Many data analysis tools and algorithms, such as machine learning algorithms, are designed to work with numerical data. Representing text as numerical data enables the use of these tools and algorithms, which can provide valuable insights into the data.\n",
        "* Improved data processing speed: Numerical data is typically easier and faster to process than text data, as the algorithms and tools used for numerical data processing are optimized for speed and efficiency.\n",
        "* Dimensionality reduction: Representing text as numerical data often involves dimensionality reduction, which is the process of reducing the number of variables in a dataset. This can simplify the data and make it easier to analyze and interpret.\n",
        "* Better representation of similarity and relationships: Representing text as numerical data can provide a better representation of similarity and relationships between documents or words. For example, the similarity between two documents can be measured using the cosine similarity between their numerical representations.\n",
        "\n",
        "\n",
        "\n",
        "2. Which of the above feature engineering techniques is considered to be more efficient and why?\n",
        "\n",
        "\n",
        "The efficiency of feature engineering techniques varies depending on the specific task, the data being used, and the desired outcome. There is no one-size-fits-all answer to which technique is more efficient.\n",
        "\n",
        "For example, normalization may be considered efficient in certain scenarios where the feature values are on vastly different scales, while one-hot encoding may be more efficient in situations where there are many categorical variables with many possible values.\n",
        "\n",
        "In general, the efficiency of a feature engineering technique depends on how well it captures the underlying relationships in the data, and how well it helps the machine learning model make predictions. It's important to experiment with different techniques and evaluate their performance on the task at hand in order to determine the most efficient one.\n"
      ],
      "metadata": {
        "id": "nD-CRWqIsLTe"
      }
    }
  ]
}