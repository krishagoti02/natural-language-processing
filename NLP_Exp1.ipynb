{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **EXPERIMENT 1**"
      ],
      "metadata": {
        "id": "LHDgSmoKqEzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Name : Krisha Goti\n",
        "# Roll No : C035\n",
        "# Program : BTI\n",
        "# Division : B\n",
        "# Date of Experiment : 22/12/2022\n",
        "# Date of Submission : 1/3/2023"
      ],
      "metadata": {
        "id": "hq4AaK1AqDl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B.1 Tasks given in PART A to be completed here**"
      ],
      "metadata": {
        "id": "cxBxBPT0ruor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A.5.1. Task\n",
        "Take a corpus from authentic sources like Kaggle and similar sources. Implement the Text Preprocessing (stop word removal, tokenization, stemming, lemmatization, TF-IDF etc.) using SpaCy and NLTK\n"
      ],
      "metadata": {
        "id": "DGgsZqN9ryUf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt4C0xbMd6Zh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaf6b235-6a32-4ccb-fd3e-4a1dca5ac0fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import spacy\n",
        "#importing random expression\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('netflix_titles.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "oV_ICWTpd-V4",
        "outputId": "ddcce646-4357-4b4d-aa6b-99fea3d5a736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  show_id     type                  title         director  \\\n",
              "0      s1    Movie   Dick Johnson Is Dead  Kirsten Johnson   \n",
              "1      s2  TV Show          Blood & Water              NaN   \n",
              "2      s3  TV Show              Ganglands  Julien Leclercq   \n",
              "3      s4  TV Show  Jailbirds New Orleans              NaN   \n",
              "4      s5  TV Show           Kota Factory              NaN   \n",
              "\n",
              "                                                cast        country  \\\n",
              "0                                                NaN  United States   \n",
              "1  Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...   South Africa   \n",
              "2  Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...            NaN   \n",
              "3                                                NaN            NaN   \n",
              "4  Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...          India   \n",
              "\n",
              "           date_added  release_year rating   duration  \\\n",
              "0  September 25, 2021          2020  PG-13     90 min   \n",
              "1  September 24, 2021          2021  TV-MA  2 Seasons   \n",
              "2  September 24, 2021          2021  TV-MA   1 Season   \n",
              "3  September 24, 2021          2021  TV-MA   1 Season   \n",
              "4  September 24, 2021          2021  TV-MA  2 Seasons   \n",
              "\n",
              "                                           listed_in  \\\n",
              "0                                      Documentaries   \n",
              "1    International TV Shows, TV Dramas, TV Mysteries   \n",
              "2  Crime TV Shows, International TV Shows, TV Act...   \n",
              "3                             Docuseries, Reality TV   \n",
              "4  International TV Shows, Romantic TV Shows, TV ...   \n",
              "\n",
              "                                         description  \n",
              "0  As her father nears the end of his life, filmm...  \n",
              "1  After crossing paths at a party, a Cape Town t...  \n",
              "2  To protect his family from a powerful drug lor...  \n",
              "3  Feuds, flirtations and toilet talk go down amo...  \n",
              "4  In a city of coaching centers known to train I...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6fb4c21-ca8a-4472-b0ef-e25209ed041c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>show_id</th>\n",
              "      <th>type</th>\n",
              "      <th>title</th>\n",
              "      <th>director</th>\n",
              "      <th>cast</th>\n",
              "      <th>country</th>\n",
              "      <th>date_added</th>\n",
              "      <th>release_year</th>\n",
              "      <th>rating</th>\n",
              "      <th>duration</th>\n",
              "      <th>listed_in</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>s1</td>\n",
              "      <td>Movie</td>\n",
              "      <td>Dick Johnson Is Dead</td>\n",
              "      <td>Kirsten Johnson</td>\n",
              "      <td>NaN</td>\n",
              "      <td>United States</td>\n",
              "      <td>September 25, 2021</td>\n",
              "      <td>2020</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>90 min</td>\n",
              "      <td>Documentaries</td>\n",
              "      <td>As her father nears the end of his life, filmm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>s2</td>\n",
              "      <td>TV Show</td>\n",
              "      <td>Blood &amp; Water</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...</td>\n",
              "      <td>South Africa</td>\n",
              "      <td>September 24, 2021</td>\n",
              "      <td>2021</td>\n",
              "      <td>TV-MA</td>\n",
              "      <td>2 Seasons</td>\n",
              "      <td>International TV Shows, TV Dramas, TV Mysteries</td>\n",
              "      <td>After crossing paths at a party, a Cape Town t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>s3</td>\n",
              "      <td>TV Show</td>\n",
              "      <td>Ganglands</td>\n",
              "      <td>Julien Leclercq</td>\n",
              "      <td>Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>September 24, 2021</td>\n",
              "      <td>2021</td>\n",
              "      <td>TV-MA</td>\n",
              "      <td>1 Season</td>\n",
              "      <td>Crime TV Shows, International TV Shows, TV Act...</td>\n",
              "      <td>To protect his family from a powerful drug lor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>s4</td>\n",
              "      <td>TV Show</td>\n",
              "      <td>Jailbirds New Orleans</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>September 24, 2021</td>\n",
              "      <td>2021</td>\n",
              "      <td>TV-MA</td>\n",
              "      <td>1 Season</td>\n",
              "      <td>Docuseries, Reality TV</td>\n",
              "      <td>Feuds, flirtations and toilet talk go down amo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>s5</td>\n",
              "      <td>TV Show</td>\n",
              "      <td>Kota Factory</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...</td>\n",
              "      <td>India</td>\n",
              "      <td>September 24, 2021</td>\n",
              "      <td>2021</td>\n",
              "      <td>TV-MA</td>\n",
              "      <td>2 Seasons</td>\n",
              "      <td>International TV Shows, Romantic TV Shows, TV ...</td>\n",
              "      <td>In a city of coaching centers known to train I...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6fb4c21-ca8a-4472-b0ef-e25209ed041c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d6fb4c21-ca8a-4472-b0ef-e25209ed041c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d6fb4c21-ca8a-4472-b0ef-e25209ed041c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df['listed_in']\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVThqUQpeWgE",
        "outputId": "4e6d3157-2704-4cb9-c8cb-aa84da24848d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                           Documentaries\n",
              "1         International TV Shows, TV Dramas, TV Mysteries\n",
              "2       Crime TV Shows, International TV Shows, TV Act...\n",
              "3                                  Docuseries, Reality TV\n",
              "4       International TV Shows, Romantic TV Shows, TV ...\n",
              "                              ...                        \n",
              "8802                       Cult Movies, Dramas, Thrillers\n",
              "8803               Kids' TV, Korean TV Shows, TV Comedies\n",
              "8804                              Comedies, Horror Movies\n",
              "8805                   Children & Family Movies, Comedies\n",
              "8806       Dramas, International Movies, Music & Musicals\n",
              "Name: listed_in, Length: 8807, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removing punctuation marks\n",
        "import string\n",
        "corpus_new = df.str.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "print(corpus_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr5AYuqMgb3T",
        "outputId": "b9a6d9b1-1f8f-4792-c6ed-27ce42dd7594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                                           Documentaries\n",
            "1           International TV Shows TV Dramas TV Mysteries\n",
            "2       Crime TV Shows International TV Shows TV Actio...\n",
            "3                                   Docuseries Reality TV\n",
            "4       International TV Shows Romantic TV Shows TV Co...\n",
            "                              ...                        \n",
            "8802                         Cult Movies Dramas Thrillers\n",
            "8803                  Kids TV Korean TV Shows TV Comedies\n",
            "8804                               Comedies Horror Movies\n",
            "8805                     Children  Family Movies Comedies\n",
            "8806          Dramas International Movies Music  Musicals\n",
            "Name: listed_in, Length: 8807, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the corpus to lower case\n",
        "corpus_lower = corpus_new.str.lower()\n",
        "print(corpus_lower)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfBpGeM9fG1E",
        "outputId": "ae3fd048-1509-4f3f-ab5c-eb6bd7bd63bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                                           documentaries\n",
            "1           international tv shows tv dramas tv mysteries\n",
            "2       crime tv shows international tv shows tv actio...\n",
            "3                                   docuseries reality tv\n",
            "4       international tv shows romantic tv shows tv co...\n",
            "                              ...                        \n",
            "8802                         cult movies dramas thrillers\n",
            "8803                  kids tv korean tv shows tv comedies\n",
            "8804                               comedies horror movies\n",
            "8805                     children  family movies comedies\n",
            "8806          dramas international movies music  musicals\n",
            "Name: listed_in, Length: 8807, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# substituting digit by space\n",
        "corpus_new = re.sub(r'\\d+', ' ', str(corpus_lower))\n",
        "print(corpus_new)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfPM87KDfTa8",
        "outputId": "81d8ce06-5385-483f-b80a-0fa2d2febab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            documentaries\n",
            "            international tv shows tv dramas tv mysteries\n",
            "        crime tv shows international tv shows tv actio...\n",
            "                                    docuseries reality tv\n",
            "        international tv shows romantic tv shows tv co...\n",
            "                              ...                        \n",
            "                          cult movies dramas thrillers\n",
            "                   kids tv korean tv shows tv comedies\n",
            "                                comedies horror movies\n",
            "                      children  family movies comedies\n",
            "           dramas international movies music  musicals\n",
            "Name: listed_in, Length:  , dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "from nltk.tokenize import word_tokenize\n",
        "from pprint import pprint # used for beautifying the print text\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MBacyBgiuK6",
        "outputId": "29394f32-002c-4eb9-b75d-c2ed60e5ec72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize stopwords\n",
        "stop_words_nltk = set(stopwords.words('english'))\n",
        "print(stop_words_nltk)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7OaPS5cjcqR",
        "outputId": "d3397402-b786-4025-eea1-b4fbf9898239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"haven't\", 'hadn', 'isn', 'of', 'not', 'his', 'did', 'off', 'o', 'hers', 'her', 'who', 'you', 'into', 'ours', 'other', 'will', \"doesn't\", 'in', 'some', 'too', 'or', 'before', 'our', 'which', 'as', 'yours', 'yourself', 'out', 're', 'was', 'mightn', 'itself', 'being', \"should've\", 'more', \"aren't\", 'hasn', 'ourselves', 'under', 'been', 'y', 'wouldn', 've', \"you'll\", 'when', 'should', 'we', 'further', 'don', 'having', 'very', 'weren', 'until', 'is', \"shouldn't\", 'against', \"that'll\", \"mightn't\", 'again', 'above', 'from', 'them', 'himself', 'here', 'i', 'after', 'just', 'this', \"she's\", 'needn', 'the', 'how', 'that', 'had', 'by', 'nor', 'during', \"weren't\", \"wouldn't\", \"you'd\", 'won', 'couldn', 'while', 'same', 'all', 'your', 'these', 'such', 'if', 'didn', \"isn't\", 'my', 'doing', 'for', 'where', \"you've\", 'down', 'on', 'so', 's', 'about', 'myself', 'wasn', \"hadn't\", 'him', 't', 'they', 'its', 'theirs', 'once', 'yourselves', 'because', 'herself', 'own', 'with', 'doesn', \"it's\", 'at', \"you're\", 'and', 'only', 'shouldn', 'whom', \"don't\", 'there', 'no', 'haven', 'shan', \"won't\", 'why', 'ma', 'than', 'are', 'me', 'below', 'does', 'their', 'then', \"didn't\", 'up', 'now', 'an', 'between', 'were', 'over', 'll', 'what', 'has', 'do', 'am', 'ain', 'can', 'be', 'themselves', 'she', 'have', 'd', 'mustn', \"hasn't\", \"mustn't\", \"wasn't\", 'to', \"needn't\", 'both', 'it', 'aren', 'but', 'through', 'few', 'any', \"couldn't\", 'each', 'a', 'm', 'most', 'he', \"shan't\", 'those'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "without_stop = remove_stopwords(corpus_new)\n",
        "print(without_stop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFTegsXSlqMz",
        "outputId": "c24a5df7-193c-41cf-b913-d5dddca3faa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "documentaries international tv shows tv dramas tv mysteries crime tv shows international tv shows tv actio... docuseries reality tv international tv shows romantic tv shows tv co... ... cult movies dramas thrillers kids tv korean tv shows tv comedies comedies horror movies children family movies comedies dramas international movies music musicals Name: listed_in, Length: , dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the corpus\n",
        "tokenized_corpus_nltk = word_tokenize(without_stop)\n",
        "print(tokenized_corpus_nltk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xVNyRChjkT5",
        "outputId": "ec6387d9-3a6e-400b-9ccf-b5d4eecc13a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['documentaries', 'international', 'tv', 'shows', 'tv', 'dramas', 'tv', 'mysteries', 'crime', 'tv', 'shows', 'international', 'tv', 'shows', 'tv', 'actio', '...', 'docuseries', 'reality', 'tv', 'international', 'tv', 'shows', 'romantic', 'tv', 'shows', 'tv', 'co', '...', '...', 'cult', 'movies', 'dramas', 'thrillers', 'kids', 'tv', 'korean', 'tv', 'shows', 'tv', 'comedies', 'comedies', 'horror', 'movies', 'children', 'family', 'movies', 'comedies', 'dramas', 'international', 'movies', 'music', 'musicals', 'Name', ':', 'listed_in', ',', 'Length', ':', ',', 'dtype', ':', 'object']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer= PorterStemmer()\n",
        "print(\"Before Stemming:\")\n",
        "print(without_stop)\n",
        "print(\"After Stemming:\")\n",
        "for word in tokenized_corpus_nltk:\n",
        "  print(stemmer.stem(word),end=\" \")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1UtpyN9lRur",
        "outputId": "53ce7c55-e177-4ba2-d117-ada29eaf1951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Stemming:\n",
            "documentaries international tv shows tv dramas tv mysteries crime tv shows international tv shows tv actio... docuseries reality tv international tv shows romantic tv shows tv co... ... cult movies dramas thrillers kids tv korean tv shows tv comedies comedies horror movies children family movies comedies dramas international movies music musicals Name: listed_in, Length: , dtype: object\n",
            "After Stemming:\n",
            "documentari intern tv show tv drama tv mysteri crime tv show intern tv show tv actio ... docuseri realiti tv intern tv show romant tv show tv co ... ... cult movi drama thriller kid tv korean tv show tv comedi comedi horror movi children famili movi comedi drama intern movi music music name : listed_in , length : , dtype : object "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "import nltk\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObC4d-uOaSSl",
        "outputId": "53cb56d5-954b-4968-92f8-51747998a93a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lemetizing the text\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "print(\"After Lemetization:\")\n",
        "lemm = WordNetLemmatizer()\n",
        "for word in tokenized_corpus_nltk:\n",
        "  print(lemm.lemmatize(word),end=\" \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7guJWM5ZlQz",
        "outputId": "d12635d2-6d9b-441f-90f3-daa44902e625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Lemetization:\n",
            "documentary international tv show tv drama tv mystery crime tv show international tv show tv actio ... docuseries reality tv international tv show romantic tv show tv co ... ... cult movie drama thriller kid tv korean tv show tv comedy comedy horror movie child family movie comedy drama international movie music musical Name : listed_in , Length : , dtype : object "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# POS tagging\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "print(\"POS Tagging using NLTK:\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ToVmH3dZ0Cg",
        "outputId": "51adf42b-4ba5-4197-e9dc-c765dda67358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tagging using NLTK:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF From Scratch"
      ],
      "metadata": {
        "id": "pMnvIIIjltCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"She asked the question even though she didn't really want to hear the answer. It was a no-win situation since she already knew. If he told the truth, she'd get confirmation of her worst fears. If he lied, she'd know that he wasn't who she thought he was which would be almost as bad. Yet she asked the question anyway and waited for his answer.\"\n",
        "text2 = \"Another writing challenge can be to take the individual sentences in the random paragraph and incorporate a single sentence from that into a new paragraph to create a short story. Unlike the random sentence generator, the sentences from the random paragraph will have some connection to one another so it will be a bit different. You also won't know exactly how many sentences will appear in the random paragraph\""
      ],
      "metadata": {
        "id": "OYw0yJS7lhx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing\n",
        "words1 = text1.lower()\n",
        "words2 = text2.lower()\n",
        "\n",
        "import string\n",
        "punc_remove1 = words1.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "punc_remove2 = words2.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "# print(punc_remove)\n",
        "\n",
        "import re\n",
        "replace_digit1 = re.sub(r'\\d+', ' ', str(punc_remove1))\n",
        "replace_digit2 = re.sub(r'\\d+', ' ', str(punc_remove2))\n",
        "# print(replace_digit)\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from pprint import pprint # used for beautifying the print text\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "# initialize stopwords\n",
        "stop_words_nltk = set(stopwords.words('english'))\n",
        "# print(stop_words_nltk)\n",
        "\n",
        "import gensim\n",
        "from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS\n",
        "without_stop1 = remove_stopwords(replace_digit1)\n",
        "without_stop2 = remove_stopwords(replace_digit2)\n",
        "# print(without_stop)\n",
        "\n",
        "words1 = word_tokenize(without_stop1)\n",
        "words2 = word_tokenize(without_stop2)\n",
        "print(words1)\n",
        "print(words2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfYNgj5Bl17p",
        "outputId": "6e0298db-8caa-4a05-ddfe-ee42604d23d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['asked', 'question', 'didnt', 'want', 'hear', 'answer', 'nowin', 'situation', 'knew', 'told', 'truth', 'shed', 'confirmation', 'worst', 'fears', 'lied', 'shed', 'know', 'wasnt', 'thought', 'bad', 'asked', 'question', 'waited', 'answer']\n",
            "['writing', 'challenge', 'individual', 'sentences', 'random', 'paragraph', 'incorporate', 'single', 'sentence', 'new', 'paragraph', 'create', 'short', 'story', 'unlike', 'random', 'sentence', 'generator', 'sentences', 'random', 'paragraph', 'connection', 'bit', 'different', 'wont', 'know', 'exactly', 'sentences', 'appear', 'random', 'paragraph']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uniqueWords = set(words1).union(set(words2))"
      ],
      "metadata": {
        "id": "bCYfOK8Fl14o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numOfWords1 = dict.fromkeys(uniqueWords, 0)\n",
        "for word in words1:\n",
        "    numOfWords1[word] += 1\n",
        "\n",
        "numOfWords2 = dict.fromkeys(uniqueWords, 0)\n",
        "\n",
        "for word in words2:\n",
        "    numOfWords2[word] += 1"
      ],
      "metadata": {
        "id": "HFpf6tngl103"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def computeTF(wordDict, bagOfWords):\n",
        "    tfDict = {}\n",
        "    bagOfWordsCount = len(bagOfWords)\n",
        "    for word, count in wordDict.items():\n",
        "        tfDict[word] = count / float(bagOfWordsCount)\n",
        "    return tfDict"
      ],
      "metadata": {
        "id": "GGnuYDtcl1y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf1 = computeTF(numOfWords1, words1)\n",
        "tf2 = computeTF(numOfWords2, words2)"
      ],
      "metadata": {
        "id": "Sh0fm_BDmfe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def computeIDF(documents):\n",
        "    import math\n",
        "    N = len(documents)\n",
        "\n",
        "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
        "    for document in documents:\n",
        "        for word, val in document.items():\n",
        "            if val > 0:\n",
        "                idfDict[word] += 1\n",
        "\n",
        "    for word, val in idfDict.items():\n",
        "        idfDict[word] = math.log(N / float(val))\n",
        "    return idfDict"
      ],
      "metadata": {
        "id": "GIKclnKqmfao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idfs = computeIDF([numOfWords1, numOfWords2])"
      ],
      "metadata": {
        "id": "7GR6_Pt8mfYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def computeTFIDF(tfBagOfWords, idfs):\n",
        "    tfidf = {}\n",
        "    for word, val in tfBagOfWords.items():\n",
        "        tfidf[word] = val * idfs[word]\n",
        "    return tfidf"
      ],
      "metadata": {
        "id": "xObXUZ0RmkBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf1 = computeTFIDF(tf1, idfs)\n",
        "tfidf2 = computeTFIDF(tf2, idfs)\n",
        "df = pd.DataFrame([tfidf1, tfidf2])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "AwGAd48cmj3R",
        "outputId": "730982bd-ad69-4ed3-ed1f-9a33c1e2f38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   situation     truth  individual  sentences      bit     worst      want  \\\n",
              "0   0.027726  0.027726     0.00000   0.000000  0.00000  0.027726  0.027726   \n",
              "1   0.000000  0.000000     0.02236   0.067079  0.02236  0.000000  0.000000   \n",
              "\n",
              "      fears  sentence      knew  ...  know    story  incorporate  challenge  \\\n",
              "0  0.027726  0.000000  0.027726  ...   0.0  0.00000      0.00000    0.00000   \n",
              "1  0.000000  0.044719  0.000000  ...   0.0  0.02236      0.02236    0.02236   \n",
              "\n",
              "       shed      told   unlike     didnt   appear  paragraph  \n",
              "0  0.055452  0.027726  0.00000  0.027726  0.00000   0.000000  \n",
              "1  0.000000  0.000000  0.02236  0.000000  0.02236   0.089438  \n",
              "\n",
              "[2 rows x 42 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-135465ca-6c0f-43ff-98b4-bd38baaf24ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>situation</th>\n",
              "      <th>truth</th>\n",
              "      <th>individual</th>\n",
              "      <th>sentences</th>\n",
              "      <th>bit</th>\n",
              "      <th>worst</th>\n",
              "      <th>want</th>\n",
              "      <th>fears</th>\n",
              "      <th>sentence</th>\n",
              "      <th>knew</th>\n",
              "      <th>...</th>\n",
              "      <th>know</th>\n",
              "      <th>story</th>\n",
              "      <th>incorporate</th>\n",
              "      <th>challenge</th>\n",
              "      <th>shed</th>\n",
              "      <th>told</th>\n",
              "      <th>unlike</th>\n",
              "      <th>didnt</th>\n",
              "      <th>appear</th>\n",
              "      <th>paragraph</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.027726</td>\n",
              "      <td>0.027726</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.027726</td>\n",
              "      <td>0.027726</td>\n",
              "      <td>0.027726</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.027726</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.055452</td>\n",
              "      <td>0.027726</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.027726</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.02236</td>\n",
              "      <td>0.067079</td>\n",
              "      <td>0.02236</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.044719</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.02236</td>\n",
              "      <td>0.02236</td>\n",
              "      <td>0.02236</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.02236</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.02236</td>\n",
              "      <td>0.089438</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 42 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-135465ca-6c0f-43ff-98b4-bd38baaf24ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-135465ca-6c0f-43ff-98b4-bd38baaf24ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-135465ca-6c0f-43ff-98b4-bd38baaf24ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF Vectorize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(words1, words2)\n",
        "feature_names = vectorizer.get_feature_names()\n",
        "# dense = vectors.todense()\n",
        "# denselist = dense.tolist()\n",
        "# df = pd.DataFrame(denselist, columns=feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI4WZZNWQsID",
        "outputId": "5bd7c261-9580-4b0a-b30f-f5f6ccb621c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JhXYu_Gmne8",
        "outputId": "a9cd5781-1f2a-480e-cc8f-67a8d95cf3db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['answer', 'asked', 'bad', 'confirmation', 'didnt', 'fears', 'hear', 'knew', 'know', 'lied', 'nowin', 'question', 'shed', 'situation', 'thought', 'told', 'truth', 'waited', 'want', 'wasnt', 'worst']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nidf values:')\n",
        "for ele1, ele2 in zip(vectorizer.get_feature_names(), vectorizer.idf_):\n",
        "\tprint(ele1, ':', ele2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7utDoXvm6G8",
        "outputId": "bdc651b5-23f8-4002-8e39-5cb9e016e66e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "idf values:\n",
            "answer : 3.159484249353372\n",
            "asked : 3.159484249353372\n",
            "bad : 3.5649493574615367\n",
            "confirmation : 3.5649493574615367\n",
            "didnt : 3.5649493574615367\n",
            "fears : 3.5649493574615367\n",
            "hear : 3.5649493574615367\n",
            "knew : 3.5649493574615367\n",
            "know : 3.5649493574615367\n",
            "lied : 3.5649493574615367\n",
            "nowin : 3.5649493574615367\n",
            "question : 3.159484249353372\n",
            "shed : 3.159484249353372\n",
            "situation : 3.5649493574615367\n",
            "thought : 3.5649493574615367\n",
            "told : 3.5649493574615367\n",
            "truth : 3.5649493574615367\n",
            "waited : 3.5649493574615367\n",
            "want : 3.5649493574615367\n",
            "wasnt : 3.5649493574615367\n",
            "worst : 3.5649493574615367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get indexing\n",
        "print('\\nWord indexes:')\n",
        "print(vectorizer.vocabulary_)\n",
        "\n",
        "# display tf-idf values\n",
        "print('\\ntf-idf value:')\n",
        "print(vectors)\n",
        "\n",
        "# in matrix form\n",
        "print('\\ntf-idf values in matrix form:')\n",
        "print(vectors.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWjaAMqMm8FI",
        "outputId": "15f91c83-d2f9-48ac-9424-427427931495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word indexes:\n",
            "{'asked': 1, 'question': 11, 'didnt': 4, 'want': 18, 'hear': 6, 'answer': 0, 'nowin': 10, 'situation': 13, 'knew': 7, 'told': 15, 'truth': 16, 'shed': 12, 'confirmation': 3, 'worst': 20, 'fears': 5, 'lied': 9, 'know': 8, 'wasnt': 19, 'thought': 14, 'bad': 2, 'waited': 17}\n",
            "\n",
            "tf-idf value:\n",
            "  (0, 1)\t1.0\n",
            "  (1, 11)\t1.0\n",
            "  (2, 4)\t1.0\n",
            "  (3, 18)\t1.0\n",
            "  (4, 6)\t1.0\n",
            "  (5, 0)\t1.0\n",
            "  (6, 10)\t1.0\n",
            "  (7, 13)\t1.0\n",
            "  (8, 7)\t1.0\n",
            "  (9, 15)\t1.0\n",
            "  (10, 16)\t1.0\n",
            "  (11, 12)\t1.0\n",
            "  (12, 3)\t1.0\n",
            "  (13, 20)\t1.0\n",
            "  (14, 5)\t1.0\n",
            "  (15, 9)\t1.0\n",
            "  (16, 12)\t1.0\n",
            "  (17, 8)\t1.0\n",
            "  (18, 19)\t1.0\n",
            "  (19, 14)\t1.0\n",
            "  (20, 2)\t1.0\n",
            "  (21, 1)\t1.0\n",
            "  (22, 11)\t1.0\n",
            "  (23, 17)\t1.0\n",
            "  (24, 0)\t1.0\n",
            "\n",
            "tf-idf values in matrix form:\n",
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B.2 Observations and Learning:**\n"
      ],
      "metadata": {
        "id": "ePWJZAMVqlwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this experiment we have observed and studied about Text Preprocessing (stop word removal, tokenization, stemming, lemmatization, TF-IDF etc.) using SpaCy and NLTK.\n"
      ],
      "metadata": {
        "id": "4Pf-KuQYqrRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B.3 Conclusion:**"
      ],
      "metadata": {
        "id": "GD0ucgCOq1Tz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After successfully completing this experiment we are able to:\n",
        "Understand basic concepts of text processing\n",
        "Design, Implement and test models for different NLP applications using statistical and sequence models.\n"
      ],
      "metadata": {
        "id": "GxIpXmKMq4WB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B.4 Question of curiosity:**"
      ],
      "metadata": {
        "id": "yTwzmb3Xq5ZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is the advantage of normalizing a word?**\n",
        "\n",
        "(a) It helps in reducing the randomness in the word\n",
        "When we normalize a text using any normalization technique, we actually reduce the word into its base form. A word may be used in different tenses according to the grammar. For example, working, worked, and works all refer to the same root word ‘work’.  Hence, converting these words into root reduces three different occurrences of a word into one. This helps a lot in NLP.\n",
        "\n",
        "(b) It reduces the dimensionality of the input\n",
        "As mentioned above, it reduces the number of unique words extracted from a corpus. In this way, it helps in reducing the dimension in machine learning task\n",
        "\n",
        "\n",
        " **2. Using TF-IDF (Term Frequency - Inverse Document Frequency) values for features in a uni-gram bag-of-words model should have an effect most similar to which pre processing technique?**\n",
        "\n",
        " Removing stop words\n",
        "TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents.\n",
        "When the metric word frequency of occurrence (TF) in a document is used as a feature value, a higher weight tends to be assigned to words that appear frequently in a corpus (such as stop-words). The inverse document frequency (IDF) is a better metric, because it assigns a lower weight to frequent words. You calculate IDF as the log of the ratio of the number of documents in the training corpus to the number of documents containing the given word. Combining these numbers in a metric (TF/IDF) places greater importance on words that are frequent in the document but rare in the corpus.\n",
        "\n",
        "\n",
        "**3. What is irregular noun Form?**\n",
        "\n",
        "Most nouns can change from singular to plural with the simple addition of an -s or an -es at the end of the noun. However, some nouns choose to be difficult, and can have a wide range of different endings when changed to their plural form! These are called irregular nouns.\n",
        "An irregular plural noun is a noun that becomes plural in a way other than adding -s or -es to the end. For example, an irregular noun like mouse changes into the plural noun mice.\n",
        "Another example is the noun thief which becomes thieves when there is more than one robber involved in a heist.\n",
        "Or, nouns like sheep or scissors look exactly the same whether these nouns are referring to one or one hundred wooly sheep or sharp scissors.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RLT4HW87rBXE"
      }
    }
  ]
}